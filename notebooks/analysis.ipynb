{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Definitions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from skbio.alignment import global_pairwise_align_protein\n",
    "from skbio.sequence import Protein, Sequence\n",
    "from skbio.sequence.distance import hamming\n",
    "from ete3 import Tree, TreeStyle, NodeStyle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam30 = pd.read_csv('../datasets/pam30.txt', sep=\"\\s+\", skiprows=9, index_col=0).to_dict()"
   ]
  },
  {
   "source": [
    "# Representants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_extended_filtered = pd.read_csv('../datasets/sequences_extended_filtered.csv').set_index('Accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'clusters.json', 'r') as f:\n",
    "    representants = [\n",
    "        sequences_extended_filtered.loc[accessions].sort_values('Collection_Date').iloc[0].name\n",
    "        for _, accessions in json.loads(f.read()).items()\n",
    "    ]\n",
    "with open(f'representants.fasta', 'w') as f:\n",
    "    response = requests.post(f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=protein&rettype=fasta&retmode=text', {'id': \",\".join(representants)})\n",
    "    f.write(response.text)"
   ]
  },
  {
   "source": [
    "# Scores and distances"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 38min 30s, sys: 1.46 s, total: 38min 32s\nWall time: 38min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proteins = sequences_extended_filtered.loc[representants]['Sequence'].apply(lambda s: Protein(s.replace('\\n', '')))\n",
    "alignments = pd.DataFrame([[global_pairwise_align_protein(p1, p2, substitution_matrix=pam30) for p1 in proteins[:i+1]] for i, p2 in enumerate(proteins)], index=representants, columns=representants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments.to_pickle('alignments.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          QOQ09568  QLG76049  QKV49386  QNO80951  QJT72902  QOF16085  \\\nQOQ09568    9685.0       NaN       NaN       NaN       NaN       NaN   \nQLG76049    9632.0    9684.0       NaN       NaN       NaN       NaN   \nQKV49386    9615.0    9622.0    9686.0       NaN       NaN       NaN   \nQNO80951    9650.0    9623.0    9606.0    9690.0       NaN       NaN   \nQJT72902    9640.0    9627.0    9610.0    9631.0    9683.0       NaN   \nQOF16085    9644.0    9631.0    9614.0    9635.0    9639.0    9688.0   \nQKF95522    9608.0    9615.0    9679.0    9599.0    9603.0    9607.0   \nQJX45344    9647.0    9634.0    9617.0    9638.0    9642.0    9646.0   \nQHD43416    9655.0    9662.0    9645.0    9646.0    9650.0    9654.0   \n\n          QKF95522  QJX45344  QHD43416  \nQOQ09568       NaN       NaN       NaN  \nQLG76049       NaN       NaN       NaN  \nQKV49386       NaN       NaN       NaN  \nQNO80951       NaN       NaN       NaN  \nQJT72902       NaN       NaN       NaN  \nQOF16085       NaN       NaN       NaN  \nQKF95522    9686.0       NaN       NaN  \nQJX45344    9610.0    9684.0       NaN  \nQHD43416    9638.0    9657.0    9685.0  \n          QOQ09568  QLG76049  QKV49386  QNO80951  QJT72902  QOF16085  \\\nQOQ09568       0.0       NaN       NaN       NaN       NaN       NaN   \nQLG76049       4.0       0.0       NaN       NaN       NaN       NaN   \nQKV49386       6.0       4.0       0.0       NaN       NaN       NaN   \nQNO80951       3.0       5.0       7.0       0.0       NaN       NaN   \nQJT72902       4.0       4.0       6.0       5.0       0.0       NaN   \nQOF16085       4.0       4.0       6.0       5.0       4.0       0.0   \nQKF95522       7.0       5.0       1.0       8.0       7.0       7.0   \nQJX45344       4.0       4.0       6.0       5.0       4.0       4.0   \nQHD43416       3.0       1.0       3.0       4.0       3.0       3.0   \n\n          QKF95522  QJX45344  QHD43416  \nQOQ09568       NaN       NaN       NaN  \nQLG76049       NaN       NaN       NaN  \nQKV49386       NaN       NaN       NaN  \nQNO80951       NaN       NaN       NaN  \nQJT72902       NaN       NaN       NaN  \nQOF16085       NaN       NaN       NaN  \nQKF95522       0.0       NaN       NaN  \nQJX45344       7.0       0.0       NaN  \nQHD43416       4.0       3.0       0.0  \n"
     ]
    }
   ],
   "source": [
    "scores = alignments.applymap(lambda x: x[1] if x else x)\n",
    "scores.to_csv('scores.csv')\n",
    "print(scores)\n",
    "distances = alignments.applymap(lambda x: hamming(x[0][0], x[0][1]) * len(x[0][0]) if x else x)\n",
    "distances.to_csv('distances.csv')\n",
    "print(distances)"
   ]
  },
  {
   "source": [
    "# UPGMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgma(distances):\n",
    "    assert distances.index.tolist() == distances.columns.tolist()\n",
    "    d = distances.to_numpy()\n",
    "    d[d == 0] = np.nan\n",
    "    d = np.tril(d) + np.tril(d).T\n",
    "    l = [(s,) for s in distances.index]\n",
    "    t = [Tree(f'{s};') for s in distances.index]\n",
    "    while len(l) > 1:\n",
    "        r, c = np.unravel_index(np.nanargmin(d, axis=None), d.shape)\n",
    "        dist = d[r, c] / 2\n",
    "        n = (d[r] * len(t[r]) + d[c] * len(t[c])) / (len(t[r]) + len(t[c]))\n",
    "        d[r,:] = n\n",
    "        d[:,r] = n.T\n",
    "        d = np.delete(d, c, 0)\n",
    "        d = np.delete(d, c, 1)\n",
    "\n",
    "        l[r] = (l[r] + l.pop(c),)\n",
    "\n",
    "        l_subtree = t[r]\n",
    "        r_subtree = t.pop(c)\n",
    "        tree = Tree()\n",
    "        tree.add_child(l_subtree, dist=dist-l_subtree.get_distance(next(l_subtree.iter_leaves())))\n",
    "        tree.add_child(r_subtree, dist=dist-r_subtree.get_distance(next(r_subtree.iter_leaves())))\n",
    "        t[r] = tree\n",
    "    return t[0]\n",
    "       "
   ]
  },
  {
   "source": [
    "%%capture\n",
    "distances = pd.read_csv('distances.csv', index_col=0)\n",
    "t = upgma(distances)\n",
    "nstyle = NodeStyle()\n",
    "nstyle[\"size\"] = 0\n",
    "for n in t.traverse():\n",
    "   n.set_style(nstyle)\n",
    "t.render('upgma.png', dpi=120, w=1200)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 40,
   "outputs": []
  },
  {
   "source": [
    "# Geography"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clusters.json', 'r') as f:\n",
    "    clusters = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================================\nValue counts for cluster #0\n\nAustralia     161\nUSA             5\nTunisia         1\nIndia           1\nBangladesh      1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #1\n\nUSA             83\nAustralia       12\nIndia            6\nChina            5\nHong Kong        3\nGreece           2\nThailand         2\nIran             2\nMalaysia         1\nGermany          1\nFrance           1\nSweden           1\nPeru             1\nEgypt            1\nSouth Korea      1\nSierra Leone     1\nTaiwan           1\nTurkey           1\nJordan           1\nPoland           1\nFinland          1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #2\n\nUSA            17\nIndia           2\nTaiwan          2\nFrance          2\nAustralia       2\nVenezuela       1\nIsrael          1\nSouth Korea     1\nIran            1\nGeorgia         1\nBangladesh      1\nHong Kong       1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #3\n\nAustralia     31\nUSA           13\nIndia          7\nEgypt          1\nIran           1\nBangladesh     1\nSpain          1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #4\n\nUSA            112\nIndia           15\nAustralia        5\nBangladesh       4\nPhilippines      2\nFrance           2\nPoland           2\nEgypt            1\nPeru             1\nGreece           1\nHong Kong        1\nMalta            1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #5\n\nUSA      9\nIndia    7\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #6\n\nUSA               3\nAustralia         2\nHong Kong         2\nSouth Korea       1\nIndia             1\nTaiwan            1\nIran              1\nUnited Kingdom    1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #7\n\nUSA           25\nBangladesh     6\nTunisia        1\nIndia          1\nName: Geo_Location, dtype: int64\n\n\n\n========================================\nValue counts for cluster #8\n\nUSA             381\nIndia            37\nAustralia        21\nBangladesh       21\nSerbia            6\nPeru              6\nFrance            6\nEgypt             5\nJapan             5\nSaudi Arabia      5\nBahrain           5\nGreece            5\nItaly             3\nMexico            2\nTurkey            2\nSpain             1\nChina             1\nPuerto Rico       1\nVenezuela         1\nJordan            1\nPoland            1\nGhana             1\nMalta             1\nHong Kong         1\nTaiwan            1\nTunisia           1\nPakistan          1\nIraq              1\nGermany           1\nBrazil            1\nBelize            1\nName: Geo_Location, dtype: int64\n\n\n\n"
     ]
    }
   ],
   "source": [
    "sequences_extended_filtered = pd.read_csv('../datasets/sequences_extended_filtered.csv').set_index('Accession')\n",
    "geo = {i: sequences_extended_filtered.loc[accessions, 'Geo_Location'].apply(lambda x: x.split(':')[0]).value_counts() for i, accessions in clusters.items()}\n",
    "for i, vc in geo.items():\n",
    "    print('='*40)\n",
    "    print(f'Value counts for cluster #{i}')\n",
    "    print()\n",
    "    print(vc)\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "source": [
    "# Mutation rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'clusters.json', 'r') as f:\n",
    "    last_representants = [\n",
    "        sequences_extended_filtered.loc[accessions].sort_values('Collection_Date', ascending=False).iloc[0].name\n",
    "        for _, accessions in json.loads(f.read()).items()\n",
    "    ]\n",
    "    last_proteins = sequences_extended_filtered.loc[last_representants]['Sequence'].apply(lambda s: Protein(s.replace('\\n', '')))\n",
    "sequences_extended = pd.read_csv('../datasets/sequences_extended.csv').set_index('Accession')\n",
    "sequences_extended['Collection_Date'] = pd.to_datetime(sequences_extended['Collection_Date'])\n",
    "YP_009724390 = Protein(sequences_extended.loc['YP_009724390', 'Sequence'].replace('\\n', ''))\n",
    "mutation_rates = [hamming(*global_pairwise_align_protein(protein, YP_009724390, substitution_matrix=pam30)[0]) * len(YP_009724390) / ((sequences_extended.loc[accession, 'Collection_Date'] - sequences_extended.loc['YP_009724390', 'Collection_Date']).days) for protein, accession in zip(last_proteins, last_representants)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.008902077151335312,\n",
       " 0.004329004329004329,\n",
       " 0.013468013468013467,\n",
       " 0.014234875444839857,\n",
       " 0.00911854103343465,\n",
       " 0.01090909090909091,\n",
       " 0.015209125475285171,\n",
       " 0.009202453987730062,\n",
       " 0.006097560975609756]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "mutation_rates"
   ]
  }
 ]
}